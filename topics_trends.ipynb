{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitenv34128bcce4524f49b7023eb817668c91",
   "display_name": "Python 3.8.5 64-bit ('env')"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import df_from_txts, add_year_column, get_topics_count, unique_path\n",
    "\n",
    "### CONFIGURATION\n",
    "\n",
    "# Paths\n",
    "from conf import CLEAN_TXT_DIR, CSV_DATA, METADATA_DIR\n",
    "\n",
    "# Topics definition\n",
    "# You should first apply LSA to the data-set in order to get an idea\n",
    "# of the main topics and keywords that define the data-set.\n",
    "# In this example, we have chosen some fields of interest, and chosen\n",
    "# the keywords that should best correlate to them, based on the LSA output.\n",
    "topics = {}\n",
    "topics[\"Medicine\"] = [\"medical\", \"patient\", \"health\", \"treatment\"]\n",
    "topics[\"ML\"] = [\"neural\", \"train\", \"recognition\", \"learn\"]\n",
    "topics[\"Aut. driving\"] = [\"vehicle\", \"autonomous\", \"park\"]\n",
    "topics[\"Quantum comput.\"] = [\"quantum\"]\n",
    "\n",
    "# Years range\n",
    "years = range(2000, 2020)\n",
    "\n",
    "\n",
    "### EXECUTION\n",
    "\n",
    "if CSV_DATA.exists():\n",
    "    df = pd.read_csv(CSV_DATA, index_col=\"ID\")\n",
    "else:\n",
    "    df = df_from_txts(CLEAN_TXT_DIR)\n",
    "    df.to_csv(CSV_DATA)\n",
    "\n",
    "df = add_year_column(df, CSV_METADATA)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute topic_year_counts matrix:\n",
    "N_TOPICS = len(topics.keys())\n",
    "N_YEARS = len(years)\n",
    "topic_year_counts = np.zeros((N_TOPICS, N_YEARS))\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    # for every year, compute topic_count_array\n",
    "    target_docs = df[df[\"Year\"] == str(year)]\n",
    "    target_txts = target_docs[\"Text\"]\n",
    "    topics_count = get_topics_count(target_txts, topics, max_count=3)\n",
    "    topic_year_counts[:,i] = np.array(topics_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOTTING\n",
    "\n",
    "# print topics\n",
    "for t in topics:\n",
    "    print(f\"{t}\")\n",
    "    print(f\" - Keywords: {topics[t]}\")\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "for i, t in enumerate(topics):\n",
    "    ax.plot(range(N_YEARS), topic_year_counts[i, :], label=t)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xticks(range(len(years)))\n",
    "ax.set_xticklabels(years)\n",
    "ax.set_ylabel(\"Number of occurences\")\n",
    "ax.set_title(\"Frequency of topic by year\")\n",
    "plt.show()"
   ]
  }
 ]
}