{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitenv34128bcce4524f49b7023eb817668c91",
   "display_name": "Python 3.8.5 64-bit ('env')",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import df_from_txts_cached, add_year_column, get_TopicDict_counts, unique_path\n",
    "\n",
    "### CONFIGURATION\n",
    "\n",
    "# Paths\n",
    "from conf import CLEAN_TXT_DIR, METADATA_CSV, CACHE_DIR\n",
    "\n",
    "# Topics definition\n",
    "# You should first apply LSA to the data-set in order to get an idea\n",
    "# of the main topics and keywords that define the data-set.\n",
    "# In this example, we have chosen some fields of interest, and chosen\n",
    "# the keywords that should best correlate to them, based on the LSA output.\n",
    "topics = {}\n",
    "topics[\"Medicine\"] = [\"medical\", \"patient\", \"health\", \"treatment\"]\n",
    "topics[\"ML\"] = [\"neural\", \"train\", \"recognition\", \"learn\"]\n",
    "topics[\"Aut. driving\"] = [\"vehicle\", \"autonomous\", \"park\"]\n",
    "topics[\"Quantum comput.\"] = [\"quantum\"]\n",
    "\n",
    "# Years range\n",
    "years = range(2000, 2020)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### EXECUTION\n",
    "\n",
    "# Merge the texts in a single csv (or use cached result)\n",
    "df = df_from_txts_cached(CLEAN_TXT_DIR, CACHE_DIR)\n",
    "# add the 'YEAR' columns\n",
    "df['Year'] = df.index.str[:4].astype(int)\n",
    "\n",
    "# Compute topic_year_counts matrix:\n",
    "N_TOPICS = len(topics.keys())\n",
    "N_YEARS = len(years)\n",
    "topic_year_counts = np.zeros((N_TOPICS, N_YEARS))\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    # for every year, compute topic_count_array\n",
    "    target_docs = df[df[\"Year\"] == year]\n",
    "    target_txts = target_docs[\"Text\"]\n",
    "    topics_count = get_TopicDict_counts(target_txts, topics, max_count=3)\n",
    "    topic_year_counts[:,i] = np.array(topics_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PLOTTING\n",
    "\n",
    "# print topics\n",
    "for t in topics:\n",
    "    print(f\"{t}\")\n",
    "    print(f\" - Keywords: {topics[t]}\")\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "for i, t in enumerate(topics):\n",
    "    ax.plot(range(N_YEARS), topic_year_counts[i, :], label=t)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xticks(range(len(years)))\n",
    "ax.set_xticklabels(years)\n",
    "ax.set_ylabel(\"Number of occurences\")\n",
    "ax.set_title(\"Frequency of topic by year\")\n",
    "plt.show()"
   ]
  }
 ]
}